{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "zlp = spacy.load('zh_core_web_lg')\n",
    "elp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nltk_tree1 = to_nltk_tree(get_root(doc1))\\nnltk_tree2 = to_nltk_tree(get_root(doc2))\\nnltk_tree1.pretty_print()\\nnltk_tree2.pretty_print()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.grammar import CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "\n",
    "def get_root(doc):\n",
    "    curr = doc[0]\n",
    "    while curr.head != curr:\n",
    "        curr = curr.head\n",
    "    return curr\n",
    "\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if len(list(node.children)) > 0:\n",
    "        return nltk.Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "'''nltk_tree1 = to_nltk_tree(get_root(doc1))\n",
    "nltk_tree2 = to_nltk_tree(get_root(doc2))\n",
    "nltk_tree1.pretty_print()\n",
    "nltk_tree2.pretty_print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, label, children=None):\n",
    "        self.label = label\n",
    "        self.children = children if children else []\n",
    "\n",
    "    def get_children(node):\n",
    "        return node.children\n",
    "\n",
    "    def get_label(node):\n",
    "        return node.label\n",
    "    \n",
    "    def complex_distance(token1, token2):\n",
    "        return 0 if set(token1.children) == set(token2.children) else (len(token1.children))\n",
    "\n",
    "def doc_to_tree(root):\n",
    "    children = list(root.children)\n",
    "    if len(children) == 0:\n",
    "        return Node(root.dep_, [])\n",
    "    else:\n",
    "        return Node(root.dep_, [doc_to_tree(child) for child in children])\n",
    "\n",
    "def pronoun_mask(tree):\n",
    "    if tree.label != 'nsubj':\n",
    "        tree.label = 0\n",
    "    else:\n",
    "        tree.label = 1\n",
    "    children = tree.get_children()\n",
    "    if len(children) > 0:\n",
    "        for child in children: child = pronoun_mask(child)\n",
    "    return tree\n",
    "\n",
    "def collapse_pronouns(root):\n",
    "    children = root.get_children()\n",
    "    leaf_sum = 0\n",
    "    branches = []\n",
    "    num_childless = 0\n",
    "    for child in children:\n",
    "        if not child.get_children():\n",
    "            leaf_sum += child.get_label()\n",
    "        else:\n",
    "            branches.append(collapse_pronouns(child))\n",
    "    return Node(root.get_label(), [Node(leaf_sum)]+branches) if root.get_children() else Node(root.get_label())\n",
    "\n",
    "def tree_to_set(root):\n",
    "\n",
    "    def helper(root, prev, level):\n",
    "        level = level\n",
    "        elems = []\n",
    "        children = root.get_children()\n",
    "        for child in children:\n",
    "            elems.append((level, prev, root.get_label(), child.get_label()))\n",
    "            elems += helper(child, level, level + 1)\n",
    "        return elems\n",
    "    \n",
    "    return [(0, -1, -1, root.get_label())] + helper(root, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, False)\n",
      "(0, 1, False)\n",
      "(0, 1, False)\n",
      "(0, 1, False)\n",
      "(0, 1, False)\n",
      "(0, 1, False)\n"
     ]
    }
   ],
   "source": [
    "doc1 = elp(\"When I came home I was tired\")\n",
    "dict = tree_to_dict(pronoun_mask(doc_to_tree(get_root(doc1))))\n",
    "\n",
    "def dict_to_set(dictionary):\n",
    "    s = set()\n",
    "    for key in dictionary:\n",
    "        nsubj = sum([tup[1] for tup in dictionary[key] if tup[2] == False])\n",
    "        for tup in dictionary[key]:\n",
    "            if tup[2] == False:\n",
    "                dictionary[key].remove(tup)\n",
    "                dictionary[key].append((tup[0], nsubj, tup[2]))\n",
    "    \n",
    "    for key in dictionary:\n",
    "        for tup in dictionary[key]:\n",
    "            print(tup)\n",
    "            #s.add(dictionary[key])\n",
    "\n",
    "dict_to_set(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(doc1, doc2):\n",
    "    set1 = set()\n",
    "    set2 = set()\n",
    "    ls1 = tree_to_dict(pronoun_mask(doc_to_tree(get_root(doc1))))\n",
    "    ls2 = tree_to_dict(pronoun_mask(doc_to_tree(get_root(doc2))))\n",
    "    for el in ls1:\n",
    "        set1.add(el)\n",
    "    for el in ls2:\n",
    "        set2.add(el)\n",
    "    return jaccard(set1, set2)\n",
    "\n",
    "def jaccard(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "     \n",
    "    return intersection / union if union else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"./xinhua_scores.csv\"), pd.read_csv(\"./xinhua_scores3.csv\"), pd.read_csv(\"./xinhua_scores1.csv\")], ignore_index=True)\n",
    "df = df.drop_duplicates(subset=['zho'], keep='first')\n",
    "df = df[df[\"zho\"] != \"\\n\"]\n",
    "df = df[[\"zho\", \"eng\", \"zho_reverse\"]]\n",
    "\n",
    "similarities1 = []\n",
    "similarities2 = []\n",
    "zh_nsubjs = []\n",
    "en_nsubjs = []\n",
    "rev_nsubjs = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    doc1 = zlp(row[\"zho\"])\n",
    "    doc2 = elp(row[\"eng\"])\n",
    "    doc3 = zlp(row[\"zho_reverse\"])\n",
    "    similarity1 = compare(doc1, doc2)\n",
    "    similarity2 = compare(doc2, doc3)\n",
    "    similarities1.append(similarity1)\n",
    "    similarities2.append(similarity2)\n",
    "    zh_nsubjs.append(len([token.dep_ for token in doc1 if token.dep_ == 'nsubj']))\n",
    "    en_nsubjs.append(len([token.dep_ for token in doc2 if token.dep_ == 'nsubj']))\n",
    "    rev_nsubjs.append(len([token.dep_ for token in doc3 if token.dep_ == 'nsubj']))\n",
    "\n",
    "df[\"zho_eng_jaccard\"] = similarities1\n",
    "df[\"eng_zho_jaccard\"] = similarities2\n",
    "df[\"zh_nsubjs\"] = zh_nsubjs\n",
    "df[\"en_nsubjs\"] = en_nsubjs\n",
    "df[\"rev_nsubjs\"] = rev_nsubjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./final_xinhua_scores.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities1 = []\n",
    "similarities2 = []\n",
    "zh_nsubjs = []\n",
    "en_nsubjs = []\n",
    "rev_nsubjs = []\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    doc1 = zlp(row[\"zho\"])\n",
    "    doc2 = elp(row[\"eng\"])\n",
    "    similarity = compare(doc1, doc2)\n",
    "    similarities1.append(similarity)\n",
    "    zh_nsubjs.append(len([token.dep_ for token in doc1 if token.dep_ == 'nsubj']))\n",
    "    en_nsubjs.append(len([token.dep_ for token in doc2 if token.dep_ == 'nsubj']))\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    doc1 = elp(row[\"eng\"])\n",
    "    doc2 = zlp(row[\"zho\"])\n",
    "    similarity = compare(doc1, doc2)\n",
    "    similarities2.append(similarity)\n",
    "    rev_nsubjs.append(len([token.dep_ for token in doc2 if token.dep_ == 'nsubj']))\n",
    "\n",
    "df1[\"zho_reverse\"] = df2[\"zho\"]\n",
    "df1[\"zho_eng_jaccard\"] = similarities1\n",
    "df1[\"eng_zho_jaccard\"] = similarities2\n",
    "df1[\"zh_nsubjs\"] = zh_nsubjs\n",
    "df1[\"en_nsubjs\"] = en_nsubjs\n",
    "df1[\"rev_nsubjs\"] = rev_nsubjs\n",
    "\n",
    "df1.to_csv(\"./xinhua_scores3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zho_eng_rev_1 = pd.read_csv('zho_eng_rev1.csv')\n",
    "\n",
    "similarities1 = []\n",
    "similarities2 = []\n",
    "zh_nsubjs = []\n",
    "en_nsubjs = []\n",
    "rev_nsubjs = []\n",
    "\n",
    "for index, row in zho_eng_rev_1.iterrows():\n",
    "    doc1 = zlp(row[\"zho\"])\n",
    "    doc2 = elp(row[\"eng\"])\n",
    "    doc3 = zlp(row[\"zho_reverse\"])\n",
    "    similarity1 = compare(doc1, doc2)\n",
    "    similarities1.append(similarity1)\n",
    "    similarity2 = compare(doc2, doc3)\n",
    "    similarities2.append(similarity2)\n",
    "    zh_nsubjs.append(len([token.dep_ for token in doc1 if token.dep_ == 'nsubj']))\n",
    "    en_nsubjs.append(len([token.dep_ for token in doc2 if token.dep_ == 'nsubj']))\n",
    "    rev_nsubjs.append(len([token.dep_ for token in doc3 if token.dep_ == 'nsubj']))\n",
    "\n",
    "zho_eng_rev_1[\"zho_reverse\"] = df2[\"zho\"]\n",
    "zho_eng_rev_1[\"zho_eng_jaccard\"] = similarities1\n",
    "zho_eng_rev_1[\"eng_zho_jaccard\"] = similarities2\n",
    "zho_eng_rev_1[\"zh_nsubjs\"] = zh_nsubjs\n",
    "zho_eng_rev_1[\"en_nsubjs\"] = en_nsubjs\n",
    "zho_eng_rev_1[\"rev_nsubjs\"] = rev_nsubjs\n",
    "\n",
    "zho_eng_rev_1.to_csv('xinhua_scores1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
